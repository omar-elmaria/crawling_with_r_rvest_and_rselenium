knitr::opts_chunk$set(echo = FALSE)
if (system.file(package = "pacman") == "") {
install.packages("pacman")
}
pacman::p_load(httr, rvest, polite, stringr)
# Try out the scrap.homegate function on "https://www.homegate.ch/mieten/3002180672"
link <- "/mieten/3002180672"
myurl <- paste("https://www.homegate.ch", link, sep="")
names1<-c("Urs","Fabienne","Fabian","Daniel","Simon","Simona","Andrea","Andreas","Martina",
"Tobias","Ruedi","Max","Susanne","Lisa","Hans","Theres","Mia")
names2<-c("Müller","Käch","Graf","Simic","DeCarli","Herrliger","Piselli","Egger","Schmucki",
"Schegg","Campi","Sonderegger")
### Scraping eröffnen ###
n1 <- sample(names1,size=1)
n2 <- sample(names2,size=1)
usera <- paste(n2,".",n1,"@",sample(c("hotmail.com","gmail.com","gmx.ch","bluewin.ch"),size=1),sep="")
mybow <- bow(myurl, user_agent=usera, force=TRUE, delay = 5.5)
mysession <- nod(bow=mybow, path=myurl)
scraped_page <- scrape(mysession)
# Send a GET request
res1 <- GET(myurl)
# Now parse its content to see what it returns
cat(content(res1, "text"))
res2 <- GET("https://httpbin.org/headers")
cat(content(res2, "text", encoding = "utf-8"))
headers = c(
"Accept" = "*/*",
"Accept-Encoding" = "gzip, deflate, br",
"Accept-Language" = "en-GB,en-US;q=0.9,en;q=0.8,de;q=0.7",
"Cookie" = "__Secure-3PAPISID=zyprGEHf3QT0pNvi/AsZUw246-p-ZUN4Wc", # I only used one Cookie out of the 4 because the other 3 are only used with http NOT https. Check the Cookies tab under "Network" for more details
"Referer" = "https://www.homegate.ch/",
"Sec-Ch-Ua" = "\"Google Chrome\";v=\"107\", \"Chromium\";v=\"107\", \"Not=A?Brand\";v=\"24\"",
"Sec-Ch-Ua-Mobile" = "?0",
"Sec-Ch-Ua-Platform" = "Windows",
"Sec-Fetch-Dest" = "script",
"Sec-Fetch-Mode" = "no-cors",
"Sec-Fetch-Site" = "cross-site",
"User-Agent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36"
)
res4 <- GET(myurl, httr::add_headers(.headers = headers))
cat(content(res4, "text", encoding = "utf-8"))
# Step 4.1: Load the RSelenium library and three other supporting libraries
pacman::p_load(RSelenium, binman, wdman, netstat)
# Step 4.2: Do four necessary steps before starting to use RSelenium **for the first time** according to this Stackoverflow
# https://stackoverflow.com/questions/46202062/i-got-error-like-error-in-if-file-accessphantompath-1-0-argument-is-o
# Step 4.2.1: Download the zip file from here according to your operating system --> http://phantomjs.org/download.html
# Step 4.2.2: Create this directory C:\Users\{Username}\AppData\Local/binman/binman_phantomjs. You will need to create two empty folders, "binman" and "binman_phantomjs"
# Step 4.2.3: Unzip the file, copy the executable in the "bin" file and paste it into the directory you created in step 4.2.2
# Step 4.2.4: Run the following two command (ONLY in the first time you use RSelenium). After the first time, you don't need to run them anymore
binman::rm_platform("phantomjs")
wdman::selenium(retcommand = TRUE)
# Step 4.2: Create a function that measures tha amount of time it takes the website to respond to a "GET" request
response_time_get <- function(webpage) {
# While scraping, we want to slow down requests to allow the page to fully load
# Since it is difficult to determine how long a page takes to load in an automated scrape, we use the solution outlined below
t0 <- Sys.time()
response <- httr::GET(webpage) # Send a request to the website
t1 <- Sys.time()
response_delay <- as.numeric(t1-t0) # Measure how long the website took to respond back to us
return(response_delay) # This will be used in the next function
}
# Step 4.3: Create a function that gets the HTML code of a webpage through RSelenium
navigate_selenium_func <- function(browser_var, webpage){
# Use RSelenium to open a blank new firefox browser according to this website
# http://joshuamccrain.com/tutorials/web_scraping_R_selenium.html
rD <- rsDriver(browser = browser_var, port = netstat::free_port(), verbose = FALSE, check = TRUE)
remDr <- rD[["client"]]
# Navigate to the required page of interest
remDr$navigate(webpage)
# Calculate the response delay, which will be used in the "sleep" function below
response_delay <- response_time_get(webpage)
# Give the page some time to fully load --> 10 times longer than response_delay to be safe
Sys.sleep(max(2.5,10 * response_delay))
# Save the HTML file to an object
html <- remDr$getPageSource()[[1]]
# Store the html code into a variable
page <- read_html(html)
# Close the browser and delete the rD variable so that you can re-use the port
remDr$close()
rD$server$stop()
rm(rD, remDr)
gc()
system("taskkill /im java.exe /f", intern=FALSE, ignore.stdout=FALSE) # Kill the Java process behind RSelenium
# Return the result (i.e. the HTML code)
return(page)
}
page <- navigate_selenium_func("firefox", "https://www.homegate.ch/mieten/3002180672")
# After you run this command, you should see a web browser popping up and the page you wanted to scrape will be displayed. The process will terminate after a few seconds and the variable "page" will contain the HTML code that can be scrapped
page
# Testing
anschrift <- page %>%
html_nodes(css = "address.AddressDetails_address_3Uq1m") %>%
html_text()
anschrift
#######################
#eröffne leere Vektoren
#######################
miete <- c(NA)
flaeche <- c(NA)
zimmer <- c(NA)
adr <- c(NA)
nettomiete <- c(NA)
nebenkosten <- c(NA)
objekt <- c(NA)
zimmer2 <- c(NA)
etage <- c(NA)
flaeche2 <- c(NA)
renovjahr <- c(NA)
baujahr <- c(NA)
allemerkmale <- c(NA)
allebeschreibung <- c(NA)
####################
#Scrap Position Top
####################
top <- page %>%
html_elements(css="ul.SpotlightAttributes_spotlight_37lw3") %>%
html_text2() %>%
stringr::str_split("\\n") %>%
unlist()
index <- which(top=="Miete")
if (length(index) > 0) {
m <- top[index + 1]
# alles was Zahl oder . ist extrahieren, oder operator ist |
m <- str_extract_all(m,"\\d|\\.")[[1]] %>% str_c(., collapse='')
miete <- c(miete, as.numeric(m))
} else {
miete<-c(miete, NA)
}
index <- which(top == "Zimmer")
if (length(index) > 0) {
z <- top[index+1]
zimmer <- c(zimmer, as.numeric(z))
} else {
zimmer <- c(zimmer, NA)
}
index <- which(top == "Fläche")
if (length(index) > 0) {
f <- top[index + 1]
f <- str_replace_all(f, "m2", "")
flaeche <- c(flaeche, as.numeric(f))
} else {
flaeche <- c(flaeche, NA)
}
########################
#Scrap Position ADRESSE
########################
myadr <- page %>%
html_nodes(css = 'address.AddressDetails_address_3Uq1m') %>%
html_text()
if (length(myadr) > 0) {
adr<-c(adr, myadr)
} else {
adr <- c(adr, NA)
}
########################
#Scrap Position KOSTEN
########################
kosten <- page %>%
html_nodes(xpath = '/html/body/div[1]/main/div/div[2]/div[1]/div[1]/div[1]/div[3]/section[1]/div[4]/div[1]') %>%
html_text2() %>%
str_split("\\n") %>%
unlist()
index <- which(kosten == "Nettomiete:")
if (length(index) > 0) {
nm <- kosten[index + 1]
# alles was Zahl oder . ist extrahieren, oder operator ist |
nm <- str_extract_all(nm, "\\d|\\.")[[1]] %>% str_c(., collapse='')
nettomiete <- c(nettomiete, as.numeric(nm))
} else {
nettomiete <- c(nettomiete, NA)
}
index <- which(kosten == "Nebenkosten:")
if (length(index) > 0) {
nk <- kosten[index+1]
# alles was Zahl oder . ist extrahieren, oder operator ist |
nk <- str_extract_all(nk, "\\d|\\.")[[1]] %>% str_c(., collapse='')
nebenkosten <- c(nebenkosten, as.numeric(nk))
} else {
nebenkosten <- c(nebenkosten, NA)
}
#########################
#Scrap Position ECKDATEN
#########################
eckdaten <- page %>%
html_nodes(css = 'div.CoreAttributes_coreAttributes_2UrTf') %>%
html_text2() %>%
str_split("\\n") %>%
unlist()
index <- which(eckdaten == "Objekttyp:")
if (length(index) > 0) {
objekt <- c(objekt, eckdaten[index + 1])
} else {
objekt <- c(objekt, NA)
}
index <- which(eckdaten == "Anzahl Zimmer:")
if(length(index) > 0) {
zimmer2 <- c(zimmer2, as.numeric(eckdaten[index + 1]))
} else {
zimmer2 <- c(zimmer2, NA)
}
index <- which(eckdaten == "Etage:")
if (length(index > 0)) {
etage <- c(etage, eckdaten[index + 1])
} else {
etage <- c(etage, NA)
}
index <- which(eckdaten == "Wohnfläche:")
if (length(index) > 0) {
flaeche2 <- c(flaeche2, as.numeric(str_replace_all(eckdaten[index + 1], "m2", "")))
} else {
flaeche2 <- c(flaeche2, NA)
}
index <- which(eckdaten == "Letztes Renovationsjahr:")
if(length(index) > 0) {
renovjahr <- c(renovjahr, as.numeric(eckdaten[index + 1]))
} else {
renovjahr <- c(renovjahr, NA)
}
index <- which(eckdaten == "Baujahr:")
if(length(index) > 0) {
baujahr <- c(baujahr, as.numeric(eckdaten[index + 1]))
} else {
baujahr <- c(baujahr, NA)
}
##########################################
#Scrap Position MERKMALE u. BESCHREIBUNG
##########################################
merkmale <- page %>%
html_elements(css = "ul.FeaturesFurnishings_list_1HzQj") %>%
html_text2()
if (length(merkmale) > 0) {
allemerkmale <- c(allemerkmale, merkmale)
} else {
allemerkmale <- c(allemerkmale, NA)
}
beschreibung <- page %>%
html_elements(css = "div.Description_descriptionBody_2wGwE") %>%
html_text2()
if (length(beschreibung) > 0) {
allebeschreibung <- c(allebeschreibung, beschreibung)
} else {
allebeschreibung <- c(allebeschreibung, NA)
}
df_result <- data.frame(
plz = myplz, miete=miete, flaeche=flaeche, zimmer=zimmer, adr=adr, nettomiete=nettomiete, nebenkosten=nebenkosten,
objekt=objekt, zimmer2=zimmer2, etage=etage, flaeche2=flaeche2, renovjahr=renovjahr, baujahr=baujahr,
allemerkmale=allemerkmale, allebeschreibung=allebeschreibung
)
df_result <- data.frame(
plz = 9050, miete=miete, flaeche=flaeche, zimmer=zimmer, adr=adr, nettomiete=nettomiete, nebenkosten=nebenkosten,
objekt=objekt, zimmer2=zimmer2, etage=etage, flaeche2=flaeche2, renovjahr=renovjahr, baujahr=baujahr,
allemerkmale=allemerkmale, allebeschreibung=allebeschreibung
)
# Display df_result
df_result <- df_result[!duplicated(df_result), ][2, ]
View(df_result)
View(df_result)
